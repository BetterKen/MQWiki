# 消息积压处理

## 1 核心思路

**快速增加消费者**

## 2 RabbitMQ处理消息堆积

**RabbitMQ可以直接增加消费者进行消费**



## 3 Kafka处理消息堆积

Kafka由于partition的扩容需要分区重新分配，在生产的同时进行数据迁移会出现重复数据。所以迁移的时候避免重复生产数据，**应该停止迁移主题的生产**。所以一般都不会进行原有topic的partition的扩容,一般kafka增加消费者的方式如下:

1. **新建一个topic，partition是原来的10倍**，临时建立好原先10倍或者20倍的queue数量

2. 然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，**直接均匀轮询写入临时建立好的10倍数量的queue**

3. 这是增加**十倍的consumer数量,订阅新的topic,**来处理堆积

4. 消费完成后需要**切换回旧的topic和consumer**

   

**这里要注意一点是consumer的数量要根据下游Mysql的最大并发来调整,不要把Mysql写挂了！**



## 4 RabbitMQ消息队列过期了怎么办

这种情况是对RabbitMQ设置了TTL,我们需要记住的原则是:

**线上不要对MQ设置TTL！即使设置了也要设置死信队列来接收!**

假如没有设置死信,消息也过期了,没有别的办法,只有**通宵熬夜补数据+写事故报告了**



## 5 消息队列快写满了怎么办

这种要分情况来看:

- 一般来说看了快写满了都是某个下游消费者出了问题造成的**,这种情况下**第一要保证的是MQ不挂**,MQ挂了导致的一系列连锁反应可以把初级程序员吓尿,**解决方式一般就是暴力的快速对消息进行消费,不做任何逻辑处理**,保证MQ不倒,然后同上一条:**通宵熬夜补数据+写事故报告了**
- 如果是因为业务量自然增长造成的快写满了,那**就需要提前进行扩容,运维做预警**,一般来说这种原因满了的话,运维也可以收拾东西领单子走人了= =||









